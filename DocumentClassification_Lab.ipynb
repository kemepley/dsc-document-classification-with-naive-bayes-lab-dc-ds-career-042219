{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with Naive Bayes - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lecture, you'll practice implementing the Naive Bayes algorithm on your own.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:  \n",
    "\n",
    "* Implement document classification using naive Bayes\n",
    "* Understand the need for the Laplacian smoothing correction\n",
    "* Explain how to code a bag of words representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset\n",
    "\n",
    "To start, import the dataset stored in the text file `SMSSpamCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SMSSpamCollection', sep='\\t', names=['class', 'text'])\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for Class Imbalance\n",
    "\n",
    "To help your algorithm perform more accurately, subset the dataset so that the two classes are of equal size. To do this, keep all of the instances of the minority class (spam) and subset examples of the majority class (ham) to an equal number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "\n",
    "ham = data[data['class']=='ham']\n",
    "ham = ham[0:747]\n",
    "spam = data[data['class']=='spam']\n",
    "ham = ham.reset_index(drop=True)\n",
    "spam = spam.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U',\n",
       " 'dun',\n",
       " 'say',\n",
       " 'so',\n",
       " 'early',\n",
       " 'hor...',\n",
       " 'U',\n",
       " 'c',\n",
       " 'already',\n",
       " 'then',\n",
       " 'say...']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham['text'][2].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split\n",
    "\n",
    "Now implement a train test split on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.concat([spam, ham], axis=0)\n",
    "\n",
    "X = df['text']\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "train_df = pd.concat([X_train, y_train], axis=1) \n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Call Germany for only 1 pence per minute! Call...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Tell them u have a headache and just want to u...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Urgent Urgent! We have 800 FREE flights to Eur...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Bears Pic Nick, and Tom, Pete and ... Dick. In...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>I don't know u and u don't know me. Send CHAT ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text class\n",
       "703  Call Germany for only 1 pence per minute! Call...  spam\n",
       "502  Tell them u have a headache and just want to u...   ham\n",
       "368  Urgent Urgent! We have 800 FREE flights to Eur...  spam\n",
       "198  Bears Pic Nick, and Tom, Pete and ... Dick. In...  spam\n",
       "336  I don't know u and u don't know me. Send CHAT ...  spam"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word frequency dictionary for each class\n",
    "\n",
    "Create a word frequency dictionary for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "ham_bag = {}\n",
    "for ind in range(len(ham)):\n",
    "    for word in ham['text'][ind].split():\n",
    "        ham_bag[word] = ham_bag.get(word, 0) + 1\n",
    "         \n",
    "spam_bag = {}\n",
    "for ind in range(len(spam)):\n",
    "    for word in spam['text'][ind].split():\n",
    "        spam_bag[word] = spam_bag.get(word, 0) + 1\n",
    "        \n",
    "class_word_freq = {} #Will be a nested dictionary of class_i : {word1:freq, word2:freq..., wordn:freq},.... class_m : {}\n",
    "class_word_freq['ham'] = ham_bag\n",
    "class_word_freq['spam'] = spam_bag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spam': 0.5, 'ham': 0.5}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_classes = dict(df['class'].value_counts(normalize=True))\n",
    "p_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the Total Corpus Words\n",
    "Calculate V, the total number of words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5926"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "# V = len(ham_bag) + len(spam_bag)\n",
    "# V\n",
    "vocabulary = set()\n",
    "for text in train_df.text:\n",
    "    for word in text.split():\n",
    "        vocabulary.add(word)\n",
    "V = len(vocabulary)\n",
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Bag of Words Function\n",
    "\n",
    "Before implementing the entire Naive Bayes algorithm, create a helper function `bag_it()` to create a bag of words representation from a document's text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "def bag_it(doc):\n",
    "    bag = {}\n",
    "    for word in doc.split():\n",
    "        bag[word] = bag.get(word, 0) +1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes\n",
    "\n",
    "Now, implement a master function to build a naive Bayes classifier. Be sure to use the logarithmic probabilities to avoid underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "def classify_doc(doc, class_word_freq, p_classes, V, return_posteriors=False):\n",
    "# using the function created earlier to create a bag of words dictionary\n",
    "    bag = bag_it(doc)\n",
    "\n",
    "    classes = []\n",
    "    posteriors = []\n",
    "\n",
    "# iterating through the dictionary containing counts of all the words in the dataframe\n",
    "    for class_ in class_word_freq.keys():\n",
    "        \n",
    "    # getting the frequency of instances of each category in the data set\n",
    "        p = np.log(p_classes[class_])\n",
    "        \n",
    "    # iterating through keys of the bag of words         \n",
    "        for word in bag.keys():\n",
    "          # the numerator is the frequency of the word in the bag +1 \n",
    "            num = bag[word]+1\n",
    "          # the denominator is the frequency of the word in the frequency dictionary for the whole data set\n",
    "            denom = class_word_freq[class_].get(word, 0) + V\n",
    "          # adding the above to p\n",
    "            p += np.log(num/denom)\n",
    "        classes.append(class_)\n",
    "        posteriors.append(p)\n",
    "        \n",
    "    if return_posteriors:\n",
    "        print(posteriors)\n",
    "        \n",
    "    return classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Out Your Classifier\n",
    "\n",
    "Finally, test out your classifier and measure its accuracy. Don't be perturbed if your results are sub-par; industry use cases would require substantial additional preprocessing before implementing the algorithm in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-192.23620607058257, -192.37826874776394]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your Code here\n",
    "classify_doc(train_df.iloc[5]['text'], class_word_freq, p_classes, V, return_posteriors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.757143\n",
       "True     0.242857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_train = X_train.map(lambda x: classify_doc(x, class_word_freq, p_classes, V))\n",
    "residuals = y_train == y_hat_train\n",
    "residuals.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Up\n",
    "\n",
    "Rework your code into an appropriate class structure so that you could easily implement the algorithm on any given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab, you practiced implementing naive Bayes' for document classification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
